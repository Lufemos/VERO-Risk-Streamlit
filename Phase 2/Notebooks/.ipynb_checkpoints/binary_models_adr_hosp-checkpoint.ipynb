{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc55fb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospitalization shape: (406, 47)\n",
      "Severe ADR shape: (406, 46)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 1\\Clean Data\"\n",
    "\n",
    "\n",
    "hosp_path  = os.path.join(BASE_DIR, \"hospitalization_model_matrix_imputed_v1.csv\")\n",
    "adr_path   = os.path.join(BASE_DIR, \"severe_adr_model_matrix_imputed_v1.csv\")\n",
    "\n",
    "\n",
    "hosp_df  = pd.read_csv(hosp_path)\n",
    "adr_df   = pd.read_csv(adr_path)\n",
    "\n",
    "\n",
    "print(\"Hospitalization shape:\", hosp_df.shape)\n",
    "print(\"Severe ADR shape:\", adr_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb6496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hosp. events:\n",
      "hospitalization_flag\n",
      "0    307\n",
      "1     99\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Severe ADR events:\n",
      "severe_adr_flag\n",
      "0    209\n",
      "1     52\n",
      "Name: count, dtype: Int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\3614344884.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  hosp_df[\"hospitalization_flag\"]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fix values like \"Yes\", \"No\", mixed cases, spaces etc.\n",
    "yes_no_map = {\n",
    "    \"yes\": 1, \"y\": 1, \"1\": 1, 1: 1, True: 1,\n",
    "    \"no\": 0, \"n\": 0, \"0\": 0, 0: 0, False: 0\n",
    "}\n",
    "\n",
    "# --- HOSPITALIZATION FLAG ---\n",
    "hosp_df[\"hospitalization_flag\"] = (\n",
    "    hosp_df[\"hospitalization_flag\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .replace(yes_no_map)\n",
    ")\n",
    "\n",
    "# Convert final values to numeric, coerce non-matching to NaN\n",
    "hosp_df[\"hospitalization_flag\"] = pd.to_numeric(\n",
    "    hosp_df[\"hospitalization_flag\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "\n",
    "# Keep only valid rows (0 or 1)\n",
    "hosp_df = hosp_df[hosp_df[\"hospitalization_flag\"].isin([0, 1])]\n",
    "\n",
    "# --- SEVERE ADR FLAG ---\n",
    "adr_model_df = adr_df.copy()\n",
    "adr_model_df[\"severe_adr_flag\"] = (\n",
    "    adr_model_df[\"severe_adr_flag\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .replace(yes_no_map)\n",
    ")\n",
    "\n",
    "adr_model_df[\"severe_adr_flag\"] = pd.to_numeric(\n",
    "    adr_model_df[\"severe_adr_flag\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "\n",
    "# Keep only valid 0/1 rows\n",
    "adr_model_df = adr_model_df[adr_model_df[\"severe_adr_flag\"].isin([0, 1])]\n",
    "\n",
    "# Summary\n",
    "print(\"Hosp. events:\")\n",
    "print(hosp_df[\"hospitalization_flag\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nSevere ADR events:\")\n",
    "print(adr_model_df[\"severe_adr_flag\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf6ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= HOSPITALIZATION =================\n",
      "ID column        : patient_id\n",
      "Outcome column(s): ['hospitalization_flag']\n",
      "Total predictors : 45\n",
      "\n",
      "01. IPB\n",
      "02. age\n",
      "03. age_group\n",
      "04. alcohol_consumption\n",
      "05. alt_gpt_range\n",
      "06. anemia_comorbidity\n",
      "07. aortic_insufficiency\n",
      "08. ast_got_range\n",
      "09. asthma\n",
      "10. atrial_fibrillation\n",
      "11. bmi_category\n",
      "12. cardiovascular_disorders\n",
      "13. cci_score\n",
      "14. cerebrovascular_disorders\n",
      "15. copd\n",
      "16. creatinine_range\n",
      "17. depressive_syndrome\n",
      "18. diabete_tipo_II\n",
      "19. direct_bilirubin_range\n",
      "20. dyslipidemia\n",
      "21. education_level\n",
      "22. employment_status\n",
      "23. ethnicity\n",
      "24. farmaci_cat_n\n",
      "25. gastroesophageal_reflux_full\n",
      "26. gastrointestinal_disorders\n",
      "27. gender\n",
      "28. genotipo_DPYD_type\n",
      "29. hemoglobin_range\n",
      "30. hypertension\n",
      "31. hypertensive_heart_disease\n",
      "32. ischemic_heart_disease\n",
      "33. molecular_alterations\n",
      "34. mutations_present\n",
      "35. neutrophils_percent_range\n",
      "36. obesity_comorbidity\n",
      "37. platelet_count_range\n",
      "38. psychiatric_disorders\n",
      "39. red_blood_cells_range\n",
      "40. renal_insufficiency\n",
      "41. smoking_status_detail\n",
      "42. total_bilirubin_range\n",
      "43. tumor_type\n",
      "44. valid_hospitalization_count\n",
      "45. white_blood_cells_range\n",
      "\n",
      "Python list ready to use:\n",
      "['IPB', 'age', 'age_group', 'alcohol_consumption', 'alt_gpt_range', 'anemia_comorbidity', 'aortic_insufficiency', 'ast_got_range', 'asthma', 'atrial_fibrillation', 'bmi_category', 'cardiovascular_disorders', 'cci_score', 'cerebrovascular_disorders', 'copd', 'creatinine_range', 'depressive_syndrome', 'diabete_tipo_II', 'direct_bilirubin_range', 'dyslipidemia', 'education_level', 'employment_status', 'ethnicity', 'farmaci_cat_n', 'gastroesophageal_reflux_full', 'gastrointestinal_disorders', 'gender', 'genotipo_DPYD_type', 'hemoglobin_range', 'hypertension', 'hypertensive_heart_disease', 'ischemic_heart_disease', 'molecular_alterations', 'mutations_present', 'neutrophils_percent_range', 'obesity_comorbidity', 'platelet_count_range', 'psychiatric_disorders', 'red_blood_cells_range', 'renal_insufficiency', 'smoking_status_detail', 'total_bilirubin_range', 'tumor_type', 'valid_hospitalization_count', 'white_blood_cells_range'] \n",
      "\n",
      "\n",
      "================= SEVERE ADR =================\n",
      "ID column        : patient_id\n",
      "Outcome column(s): ['severe_adr_flag']\n",
      "Total predictors : 44\n",
      "\n",
      "01. IPB\n",
      "02. age\n",
      "03. age_group\n",
      "04. alcohol_consumption\n",
      "05. alt_gpt_range\n",
      "06. anemia_comorbidity\n",
      "07. aortic_insufficiency\n",
      "08. ast_got_range\n",
      "09. asthma\n",
      "10. atrial_fibrillation\n",
      "11. bmi_category\n",
      "12. cardiovascular_disorders\n",
      "13. cci_score\n",
      "14. cerebrovascular_disorders\n",
      "15. copd\n",
      "16. creatinine_range\n",
      "17. depressive_syndrome\n",
      "18. diabete_tipo_II\n",
      "19. direct_bilirubin_range\n",
      "20. dyslipidemia\n",
      "21. education_level\n",
      "22. employment_status\n",
      "23. ethnicity\n",
      "24. farmaci_cat_n\n",
      "25. gastroesophageal_reflux_full\n",
      "26. gastrointestinal_disorders\n",
      "27. gender\n",
      "28. genotipo_DPYD_type\n",
      "29. hemoglobin_range\n",
      "30. hypertension\n",
      "31. hypertensive_heart_disease\n",
      "32. ischemic_heart_disease\n",
      "33. molecular_alterations\n",
      "34. mutations_present\n",
      "35. neutrophils_percent_range\n",
      "36. obesity_comorbidity\n",
      "37. platelet_count_range\n",
      "38. psychiatric_disorders\n",
      "39. red_blood_cells_range\n",
      "40. renal_insufficiency\n",
      "41. smoking_status_detail\n",
      "42. total_bilirubin_range\n",
      "43. tumor_type\n",
      "44. white_blood_cells_range\n",
      "\n",
      "Python list ready to use:\n",
      "['IPB', 'age', 'age_group', 'alcohol_consumption', 'alt_gpt_range', 'anemia_comorbidity', 'aortic_insufficiency', 'ast_got_range', 'asthma', 'atrial_fibrillation', 'bmi_category', 'cardiovascular_disorders', 'cci_score', 'cerebrovascular_disorders', 'copd', 'creatinine_range', 'depressive_syndrome', 'diabete_tipo_II', 'direct_bilirubin_range', 'dyslipidemia', 'education_level', 'employment_status', 'ethnicity', 'farmaci_cat_n', 'gastroesophageal_reflux_full', 'gastrointestinal_disorders', 'gender', 'genotipo_DPYD_type', 'hemoglobin_range', 'hypertension', 'hypertensive_heart_disease', 'ischemic_heart_disease', 'molecular_alterations', 'mutations_present', 'neutrophils_percent_range', 'obesity_comorbidity', 'platelet_count_range', 'psychiatric_disorders', 'red_blood_cells_range', 'renal_insufficiency', 'smoking_status_detail', 'total_bilirubin_range', 'tumor_type', 'white_blood_cells_range'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 1\\Clean Data\"\n",
    "\n",
    "\n",
    "hosp_path  = os.path.join(BASE_DIR, \"hospitalization_model_matrix_imputed_v1.csv\")\n",
    "adr_path   = os.path.join(BASE_DIR, \"severe_adr_model_matrix_imputed_v1.csv\")\n",
    "\n",
    "\n",
    "hosp_df  = pd.read_csv(hosp_path)\n",
    "adr_df   = pd.read_csv(adr_path)\n",
    "\n",
    "\n",
    "def inspect_covariates(df, id_col, outcome_cols, dataset_name):\n",
    "\n",
    "    predictors = [\n",
    "        col for col in df.columns\n",
    "        if col not in outcome_cols + [id_col]\n",
    "    ]\n",
    "\n",
    "    predictors_sorted = sorted(predictors)\n",
    "\n",
    "    print(f\"\\n================= {dataset_name.upper()} =================\")\n",
    "    print(f\"ID column        : {id_col}\")\n",
    "    print(f\"Outcome column(s): {outcome_cols}\")\n",
    "    print(f\"Total predictors : {len(predictors_sorted)}\\n\")\n",
    "\n",
    "    # 1. Numbered list\n",
    "    for i, col in enumerate(predictors_sorted, start=1):\n",
    "        print(f\"{i:02d}. {col}\")\n",
    "\n",
    "    # 2. Raw Python list for copy-paste into modeling code\n",
    "    print(\"\\nPython list ready to use:\")\n",
    "    print(predictors_sorted, \"\\n\")\n",
    "\n",
    "    return predictors_sorted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hosp_covariates = inspect_covariates(\n",
    "    df=hosp_df,\n",
    "    id_col=\"patient_id\",\n",
    "    outcome_cols=[\"hospitalization_flag\"],\n",
    "    dataset_name=\"Hospitalization\"\n",
    ")\n",
    "\n",
    "adr_covariates = inspect_covariates(\n",
    "    df=adr_df,\n",
    "    id_col=\"patient_id\",\n",
    "    outcome_cols=[\"severe_adr_flag\"],\n",
    "    dataset_name=\"Severe ADR\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5422283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospitalization shape: (406, 47)\n",
      "Severe ADR shape: (261, 46)\n",
      "Hosp events: hospitalization_flag\n",
      "No     307\n",
      "Yes     99\n",
      "Name: count, dtype: int64\n",
      "Severe ADR events: severe_adr_flag\n",
      "0    209\n",
      "1     52\n",
      "Name: count, dtype: Int64\n",
      "Missing hospital predictors: []\n",
      "Missing severe ADR predictors: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    classification_report, roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Base paths\n",
    "# -------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\"\n",
    "BIN_OUT_DIR = os.path.join(BASE_DIR, \"binary_models\")\n",
    "os.makedirs(BIN_OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Hospitalization shape:\", hosp_df.shape)\n",
    "print(\"Severe ADR shape:\", adr_model_df.shape)\n",
    "\n",
    "print(\"Hosp events:\", hosp_df[\"hospitalization_flag\"].value_counts())\n",
    "print(\"Severe ADR events:\", adr_model_df[\"severe_adr_flag\"].value_counts())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Predictors per outcome (FULL lists)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Hospitalization: drop hospitalization_flag and valid_hospitalization_count\n",
    "hosp_predictors = [\n",
    "   # Demographics & socio-economic\n",
    "    \"age_group\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"education_level\",\n",
    "    \"employment_status\",\n",
    "    \"bmi_category\",\n",
    "    \"smoking_status_detail\",\n",
    "    \"alcohol_consumption\",\n",
    "\n",
    "    # Frailty / vulnerability\n",
    "    \"IPB\",\n",
    "    \"cci_score\",\n",
    "\n",
    "    # Comorbidities\n",
    "    \"anemia_comorbidity\",\n",
    "    \"asthma\",\n",
    "    \"atrial_fibrillation\",\n",
    "    \"copd\",\n",
    "    \"depressive_syndrome\",\n",
    "    \"diabete_tipo_II\",\n",
    "    \"dyslipidemia\",\n",
    "    \"hypertension\",\n",
    "    \"hypertensive_heart_disease\",\n",
    "    \"ischemic_heart_disease\",\n",
    "    \"renal_insufficiency\",\n",
    "    \"obesity_comorbidity\",\n",
    "    \"psychiatric_disorders\",\n",
    "    \"cardiovascular_disorders\",\n",
    "    \"cerebrovascular_disorders\",\n",
    "    \"gastrointestinal_disorders\",\n",
    "    \"gastroesophageal_reflux_full\",\n",
    "    \"aortic_insufficiency\",\n",
    "\n",
    "    # Baseline laboratory ranges\n",
    "    \"alt_gpt_range\",\n",
    "    \"ast_got_range\",\n",
    "    \"creatinine_range\",\n",
    "    \"direct_bilirubin_range\",\n",
    "    \"total_bilirubin_range\",\n",
    "    \"hemoglobin_range\",\n",
    "    \"platelet_count_range\",\n",
    "    \"white_blood_cells_range\",\n",
    "    \"red_blood_cells_range\",\n",
    "    \"neutrophils_percent_range\",\n",
    "\n",
    "    # Oncological baseline characteristics\n",
    "    \"tumor_type\",\n",
    "    \"molecular_alterations\",\n",
    "    \"mutations_present\",\n",
    "    \"genotipo_DPYD_type\"\n",
    "]\n",
    "\n",
    "# Severe ADR (already clean)\n",
    "adr_predictors = [\n",
    "    # Demographics & socio-economic\n",
    "    \"age_group\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"education_level\",\n",
    "    \"employment_status\",\n",
    "    \"bmi_category\",\n",
    "    \"smoking_status_detail\",\n",
    "    \"alcohol_consumption\",\n",
    "\n",
    "    # Frailty / vulnerability\n",
    "    \"IPB\",\n",
    "    \"cci_score\",\n",
    "\n",
    "    # Comorbidities\n",
    "    \"anemia_comorbidity\",\n",
    "    \"asthma\",\n",
    "    \"atrial_fibrillation\",\n",
    "    \"copd\",\n",
    "    \"depressive_syndrome\",\n",
    "    \"diabete_tipo_II\",\n",
    "    \"dyslipidemia\",\n",
    "    \"hypertension\",\n",
    "    \"hypertensive_heart_disease\",\n",
    "    \"ischemic_heart_disease\",\n",
    "    \"renal_insufficiency\",\n",
    "    \"obesity_comorbidity\",\n",
    "    \"psychiatric_disorders\",\n",
    "    \"cardiovascular_disorders\",\n",
    "    \"cerebrovascular_disorders\",\n",
    "    \"gastrointestinal_disorders\",\n",
    "    \"gastroesophageal_reflux_full\",\n",
    "    \"aortic_insufficiency\",\n",
    "\n",
    "    # Baseline laboratory ranges\n",
    "    \"alt_gpt_range\",\n",
    "    \"ast_got_range\",\n",
    "    \"creatinine_range\",\n",
    "    \"direct_bilirubin_range\",\n",
    "    \"total_bilirubin_range\",\n",
    "    \"hemoglobin_range\",\n",
    "    \"platelet_count_range\",\n",
    "    \"white_blood_cells_range\",\n",
    "    \"red_blood_cells_range\",\n",
    "    \"neutrophils_percent_range\",\n",
    "\n",
    "    # Oncology & genetics\n",
    "    \"tumor_type\",\n",
    "    \"molecular_alterations\",\n",
    "    \"mutations_present\",\n",
    "    \"genotipo_DPYD_type\",\n",
    "\n",
    "    # Baseline treatment exposure (ADR-specific)\n",
    "    \"farmaci_cat_n\"\n",
    "]\n",
    "\n",
    "# Sanity check that all columns exist\n",
    "missing_h = [c for c in hosp_predictors if c not in hosp_df.columns]\n",
    "missing_a = [c for c in adr_predictors if c not in adr_model_df.columns]\n",
    "\n",
    "print(\"Missing hospital predictors:\", missing_h)\n",
    "print(\"Missing severe ADR predictors:\", missing_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b4084f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\1663681603.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[outcome_col]\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\1663681603.py:135: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(out_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate screening for Hospitalization complete. Saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\univariate_screening_hospitalization.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\1663681603.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[outcome_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate screening for Severe_ADR complete. Saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\univariate_screening_severeADR.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\1663681603.py:135: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(out_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Helper: detect binary variable\n",
    "# ---------------------------------------------\n",
    "def is_binary(series):\n",
    "    vals = series.dropna().unique()\n",
    "    return len(vals) == 2\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Core function: univariate screening for 1 binary outcome\n",
    "# ---------------------------------------------\n",
    "def run_univariate_screening_binary(df, outcome_col, feature_list, outcome_label, out_path):\n",
    "    \"\"\"\n",
    "    df           : pandas DataFrame with outcome + predictors\n",
    "    outcome_col  : binary outcome column name (0/1 or yes/no)\n",
    "    feature_list : list of predictors to test\n",
    "    outcome_label: nice label for reporting (e.g. 'Hospitalization')\n",
    "    out_path     : path to save Excel\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "\n",
    "    # --- 1) Standardise outcome to 0/1 ---\n",
    "    yes_no_map = {\n",
    "        \"yes\": 1, \"y\": 1, \"1\": 1, 1: 1, True: 1,\n",
    "        \"no\": 0, \"n\": 0, \"0\": 0, 0: 0, False: 0\n",
    "    }\n",
    "\n",
    "    # lower/strip/map where possible\n",
    "    data[outcome_col] = (\n",
    "        data[outcome_col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .replace(yes_no_map)\n",
    "    )\n",
    "\n",
    "    # coerce to numeric, non-mappable values -> NaN\n",
    "    data[outcome_col] = pd.to_numeric(data[outcome_col], errors=\"coerce\")\n",
    "\n",
    "    # keep only clean 0/1 rows\n",
    "    data = data[data[outcome_col].isin([0, 1])].copy()\n",
    "    data[outcome_col] = data[outcome_col].astype(int)\n",
    "\n",
    "    # quick check\n",
    "    if data.empty or not is_binary(data[outcome_col]):\n",
    "        print(f\"[{outcome_label}] Outcome column '{outcome_col}' is not usable as binary after cleaning.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        if feature not in data.columns:\n",
    "            continue\n",
    "\n",
    "        sub = data[[feature, outcome_col]].dropna()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        x = sub[feature]\n",
    "        y = sub[outcome_col]\n",
    "\n",
    "        # Decide type of feature\n",
    "        feat_is_num = np.issubdtype(x.dtype, np.number)\n",
    "\n",
    "        try:\n",
    "            # --- Numeric feature vs binary outcome -> t-test ---\n",
    "            if feat_is_num:\n",
    "                if not is_binary(y):\n",
    "                    continue\n",
    "                # make sure ordering is stable\n",
    "                vals = sorted(y.unique())\n",
    "                groups = [x[y == v] for v in vals]\n",
    "                if len(groups) != 2:\n",
    "                    continue\n",
    "                if len(groups[0]) < 2 or len(groups[1]) < 2:\n",
    "                    continue\n",
    "\n",
    "                t_stat, p = stats.ttest_ind(\n",
    "                    groups[0], groups[1],\n",
    "                    nan_policy=\"omit\",\n",
    "                    equal_var=False\n",
    "                )\n",
    "                test = \"T-test\"\n",
    "\n",
    "            # --- Categorical feature vs binary outcome -> Chi-square ---\n",
    "            else:\n",
    "                if not is_binary(y):\n",
    "                    continue\n",
    "                ctab = pd.crosstab(x, y)\n",
    "                # Need at least 2 levels in feature and 2 in outcome\n",
    "                if ctab.shape[0] < 2 or ctab.shape[1] < 2:\n",
    "                    continue\n",
    "\n",
    "                chi2, p, dof, ex = stats.chi2_contingency(ctab)\n",
    "                test = \"Chi-square\"\n",
    "\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": test,\n",
    "                \"P-Value\": p\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            # Track failures but mark as Error\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": \"Error\",\n",
    "                \"P-Value\": np.nan\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if not results_df.empty:\n",
    "        # FDR correction within this outcome\n",
    "        mask = results_df[\"P-Value\"].notna()\n",
    "        if mask.any():\n",
    "            _, qvals, _, _ = multipletests(\n",
    "                results_df.loc[mask, \"P-Value\"],\n",
    "                alpha=0.05,\n",
    "                method=\"fdr_bh\"\n",
    "            )\n",
    "            results_df.loc[mask, \"Corrected P-Value\"] = qvals\n",
    "\n",
    "        # Sort for readability\n",
    "        results_df = results_df.sort_values([\"P-Value\"], na_position=\"last\")\n",
    "\n",
    "        # Save\n",
    "        results_df.to_excel(out_path, index=False)\n",
    "        print(f\"Univariate screening for {outcome_label} complete. Saved to:\\n  {out_path}\")\n",
    "    else:\n",
    "        print(f\"No valid univariate comparisons for {outcome_label}.\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Run for HOSPITALIZATION\n",
    "# ------------------------------------------------\n",
    "hosp_uni_path = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"univariate_screening_hospitalization.xlsx\"\n",
    ")\n",
    "hosp_uni_results = run_univariate_screening_binary(\n",
    "    df=hosp_df,                          # can still contain \"Yes\"/\"No\"\n",
    "    outcome_col=\"hospitalization_flag\",  # will be cleaned inside\n",
    "    feature_list=hosp_predictors,\n",
    "    outcome_label=\"Hospitalization\",\n",
    "    out_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Run for SEVERE ADR\n",
    "# ------------------------------------------------\n",
    "adr_uni_path = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"univariate_screening_severeADR.xlsx\"\n",
    ")\n",
    "adr_uni_results = run_univariate_screening_binary(\n",
    "    df=adr_model_df,                     # here values might already be 0/1\n",
    "    outcome_col=\"severe_adr_flag\",\n",
    "    feature_list=adr_predictors,\n",
    "    outcome_label=\"Severe_ADR\",\n",
    "    out_path=adr_uni_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "741dd774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\2020275133.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  s = s.replace(yes_no_map)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\2020275133.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  s = s.replace(yes_no_map)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# 0) Clean / harmonize binary outcomes\n",
    "# ------------------------------------------------\n",
    "yes_no_map = {\n",
    "    \"present / yes\": 1, \"present/yes\": 1, \"present\": 1,\n",
    "    \"yes\": 1, \"y\": 1, \"1\": 1, \"true\": 1, True: 1,\n",
    "    \"absent / no\": 0, \"absent/no\": 0, \"absent\": 0,\n",
    "    \"no\": 0, \"n\": 0, \"0\": 0, \"false\": 0, False: 0\n",
    "}\n",
    "\n",
    "def clean_binary(series):\n",
    "    s = series.astype(str).str.strip().str.lower()\n",
    "    s = s.replace(yes_no_map)\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    # keep only 0/1, drop weird stuff\n",
    "    return s.where(s.isin([0, 1]))\n",
    "\n",
    "# Hospitalization\n",
    "hosp_df = hosp_df.copy()\n",
    "hosp_df[\"hospitalization_flag_clean\"] = clean_binary(hosp_df[\"hospitalization_flag\"])\n",
    "\n",
    "# Severe ADR\n",
    "adr_model_df = adr_model_df.copy()\n",
    "adr_model_df[\"severe_adr_flag_clean\"] = clean_binary(adr_model_df[\"severe_adr_flag\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8170edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from math import sqrt\n",
    "\n",
    "def is_binary(series):\n",
    "    vals = series.dropna().unique()\n",
    "    return len(vals) == 2\n",
    "\n",
    "def cohens_d(x, y):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    y = pd.to_numeric(y, errors=\"coerce\").dropna()\n",
    "    nx, ny = len(x), len(y)\n",
    "    if nx < 2 or ny < 2:\n",
    "        return np.nan\n",
    "    dof = nx + ny - 2\n",
    "    pooled_std = sqrt(((nx - 1) * x.var(ddof=1) + (ny - 1) * y.var(ddof=1)) / dof) if dof > 0 else np.nan\n",
    "    return (x.mean() - y.mean()) / pooled_std if (pooled_std is not None and pooled_std > 0) else np.nan\n",
    "\n",
    "def cramers_v(chi2, n, r, c):\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    denom = n * (min(r - 1, c - 1))\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    return sqrt(chi2 / denom)\n",
    "\n",
    "def run_univariate_with_effects(df, outcome_col, feature_list, outcome_label, save_path):\n",
    "    data = df.copy()\n",
    "    # Ensure binary 0/1 (nullable integer)\n",
    "    data[outcome_col] = pd.to_numeric(data[outcome_col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        if feature not in data.columns:\n",
    "            continue\n",
    "\n",
    "        sub = data[[feature, outcome_col]].dropna()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        x = sub[feature]\n",
    "        y = sub[outcome_col]\n",
    "\n",
    "        # Only sensible if outcome is binary\n",
    "        if not is_binary(y):\n",
    "            continue\n",
    "\n",
    "        feat_is_num = np.issubdtype(x.dtype, np.number)\n",
    "\n",
    "        try:\n",
    "            if feat_is_num:\n",
    "                groups = [x[y == val] for val in y.unique()]\n",
    "                if len(groups) != 2:\n",
    "                    continue\n",
    "                if len(groups[0]) < 2 or len(groups[1]) < 2:\n",
    "                    continue\n",
    "\n",
    "                t_stat, p = stats.ttest_ind(\n",
    "                    groups[0], groups[1],\n",
    "                    nan_policy=\"omit\",\n",
    "                    equal_var=False\n",
    "                )\n",
    "                test = \"T-test\"\n",
    "                effect_size = cohens_d(groups[0], groups[1])\n",
    "\n",
    "            else:\n",
    "                ctab = pd.crosstab(x, y)\n",
    "                if ctab.shape[0] < 2 or ctab.shape[1] < 2:\n",
    "                    continue\n",
    "\n",
    "                chi2, p, dof, ex = stats.chi2_contingency(ctab)\n",
    "                test = \"Chi-square\"\n",
    "                n = int(ctab.values.sum())\n",
    "                effect_size = cramers_v(chi2, n, *ctab.shape)\n",
    "\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": test,\n",
    "                \"P-Value\": p,\n",
    "                \"Effect Size\": effect_size\n",
    "            })\n",
    "\n",
    "        except Exception:\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": \"Error\",\n",
    "                \"P-Value\": np.nan,\n",
    "                \"Effect Size\": np.nan\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if not results_df.empty:\n",
    "        mask = results_df[\"P-Value\"].notna()\n",
    "        if mask.any():\n",
    "            _, qvals, _, _ = multipletests(\n",
    "                results_df.loc[mask, \"P-Value\"],\n",
    "                alpha=0.05,\n",
    "                method=\"fdr_bh\"\n",
    "            )\n",
    "            results_df.loc[mask, \"Corrected P-Value\"] = qvals\n",
    "\n",
    "        results_df = results_df.sort_values([\"P-Value\"], na_position=\"last\")\n",
    "        results_df.to_excel(save_path, index=False)\n",
    "        print(f\"Univariate screening for {outcome_label} complete. Saved to:\\n   {save_path}\")\n",
    "    else:\n",
    "        print(f\"No valid univariate comparisons for {outcome_label}.\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3921bd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\1771680675.py:110: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(save_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate screening for Hospitalization complete. Saved to:\n",
      "   C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\univariate_hospitalization_with_effects.xlsx\n",
      "Univariate screening for Severe_ADR complete. Saved to:\n",
      "   C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\univariate_severeADR_with_effects.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\1771680675.py:110: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(save_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "# Hospitalization (with effects)\n",
    "hosp_uni_path = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"univariate_hospitalization_with_effects.xlsx\"\n",
    ")\n",
    "hosp_uni_results = run_univariate_with_effects(\n",
    "    df=hosp_df,\n",
    "    outcome_col=\"hospitalization_flag_clean\",\n",
    "    feature_list=hosp_predictors,\n",
    "    outcome_label=\"Hospitalization\",\n",
    "    save_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "# Severe ADR (with effects)\n",
    "adr_uni_path = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"univariate_severeADR_with_effects.xlsx\"\n",
    ")\n",
    "adr_uni_results = run_univariate_with_effects(\n",
    "    df=adr_model_df,\n",
    "    outcome_col=\"severe_adr_flag_clean\",\n",
    "    feature_list=adr_predictors,\n",
    "    outcome_label=\"Severe_ADR\",\n",
    "    save_path=adr_uni_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0f8b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid univariate comparisons for Hospitalization.\n",
      "✅ Univariate screening for Severe_ADR complete. Saved to:\n",
      "   C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\univariate_screening_severeADR_with_effects.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\757564937.py:122: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(save_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from math import sqrt\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------------------------\n",
    "\n",
    "def is_binary(series):\n",
    "    vals = series.dropna().unique()\n",
    "    return len(vals) == 2\n",
    "\n",
    "# Cohen's d (for t-test)\n",
    "def cohens_d(x, y):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    y = pd.to_numeric(y, errors=\"coerce\").dropna()\n",
    "    nx, ny = len(x), len(y)\n",
    "    if nx < 2 or ny < 2:\n",
    "        return np.nan\n",
    "    dof = nx + ny - 2\n",
    "    pooled_std = sqrt(((nx - 1) * x.var(ddof=1) + (ny - 1) * y.var(ddof=1)) / dof) if dof > 0 else np.nan\n",
    "    return (x.mean() - y.mean()) / pooled_std if (pooled_std is not None and pooled_std > 0) else np.nan\n",
    "\n",
    "# Cramér's V (for Chi-square)\n",
    "def cramers_v(chi2, n, r, c):\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    denom = n * (min(r - 1, c - 1))\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    return sqrt(chi2 / denom)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Generic univariate screening for a single binary outcome\n",
    "# ------------------------------------------------\n",
    "\n",
    "def run_univariate_with_effects(df, outcome_col, feature_list, outcome_label, save_path):\n",
    "    data = df.copy()\n",
    "    # Ensure binary 0/1\n",
    "    data[outcome_col] = pd.to_numeric(data[outcome_col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        if feature not in data.columns:\n",
    "            continue\n",
    "\n",
    "        sub = data[[feature, outcome_col]].dropna()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        x = sub[feature]\n",
    "        y = sub[outcome_col]\n",
    "\n",
    "        # Only sensible to continue if outcome is binary\n",
    "        if not is_binary(y):\n",
    "            continue\n",
    "\n",
    "        feat_is_num = np.issubdtype(x.dtype, np.number)\n",
    "\n",
    "        try:\n",
    "            # Numeric feature vs binary outcome -> t-test + Cohen's d\n",
    "            if feat_is_num:\n",
    "                groups = [x[y == val] for val in y.unique()]\n",
    "                if len(groups) != 2:\n",
    "                    continue\n",
    "                if len(groups[0]) < 2 or len(groups[1]) < 2:\n",
    "                    continue\n",
    "\n",
    "                t_stat, p = stats.ttest_ind(groups[0], groups[1], nan_policy=\"omit\", equal_var=False)\n",
    "                test = \"T-test\"\n",
    "                effect_size = cohens_d(groups[0], groups[1])\n",
    "\n",
    "            # Categorical feature vs binary outcome -> Chi-square + Cramér's V\n",
    "            else:\n",
    "                ctab = pd.crosstab(x, y)\n",
    "                if ctab.shape[0] < 2 or ctab.shape[1] < 2:\n",
    "                    continue\n",
    "\n",
    "                chi2, p, dof, ex = stats.chi2_contingency(ctab)\n",
    "                test = \"Chi-square\"\n",
    "                n = int(ctab.values.sum())\n",
    "                effect_size = cramers_v(chi2, n, *ctab.shape)\n",
    "\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": test,\n",
    "                \"P-Value\": p,\n",
    "                \"Effect Size\": effect_size\n",
    "            })\n",
    "\n",
    "        except Exception:\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": \"Error\",\n",
    "                \"P-Value\": np.nan,\n",
    "                \"Effect Size\": np.nan\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if not results_df.empty:\n",
    "        # FDR correction\n",
    "        mask = results_df[\"P-Value\"].notna()\n",
    "        if mask.any():\n",
    "            _, qvals, _, _ = multipletests(\n",
    "                results_df.loc[mask, \"P-Value\"],\n",
    "                alpha=0.05,\n",
    "                method=\"fdr_bh\"\n",
    "            )\n",
    "            results_df.loc[mask, \"Corrected P-Value\"] = qvals\n",
    "\n",
    "        # Sort for readability\n",
    "        results_df = results_df.sort_values([\"P-Value\"], na_position=\"last\")\n",
    "\n",
    "        # Save\n",
    "        results_df.to_excel(save_path, index=False)\n",
    "        print(f\"✅ Univariate screening for {outcome_label} complete. Saved to:\\n   {save_path}\")\n",
    "    else:\n",
    "        print(f\"No valid univariate comparisons for {outcome_label}.\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Apply to your two models\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Assuming BASE_DIR, hosp_df, adr_model_df, hosp_predictors, adr_predictors already exist\n",
    "\n",
    "# Hospitalization\n",
    "hosp_uni_path = os.path.join(BASE_DIR, \"univariate_screening_hospitalization_with_effects.xlsx\")\n",
    "hosp_uni_results = run_univariate_with_effects(\n",
    "    df=hosp_df,\n",
    "    outcome_col=\"hospitalization_flag\",\n",
    "    feature_list=hosp_predictors,\n",
    "    outcome_label=\"Hospitalization\",\n",
    "    save_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "# Severe ADR\n",
    "adr_uni_path = os.path.join(BASE_DIR, \"univariate_screening_severeADR_with_effects.xlsx\")\n",
    "adr_uni_results = run_univariate_with_effects(\n",
    "    df=adr_model_df,\n",
    "    outcome_col=\"severe_adr_flag\",\n",
    "    feature_list=adr_predictors,\n",
    "    outcome_label=\"Severe_ADR\",\n",
    "    save_path=adr_uni_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdfe07e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations completed! PNG files saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Where results were saved\n",
    "hosp_results_file = os.path.join(BASE_DIR, \"univariate_screening_hospitalization_with_effects.xlsx\")\n",
    "adr_results_file  = os.path.join(BASE_DIR, \"univariate_screening_severeADR_with_effects.xlsx\")\n",
    "\n",
    "hosp_uni_results = pd.read_excel(hosp_results_file)\n",
    "adr_uni_results  = pd.read_excel(adr_results_file)\n",
    "\n",
    "def plot_univariate_results(df, outcome_name, top_n=15, label_n=20):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df = df[df[\"Corrected P-Value\"].notna()]\n",
    "    if df.empty:\n",
    "        print(f\"No valid univariate results for {outcome_name}.\")\n",
    "        return\n",
    "\n",
    "    # Create neg-log10 significance\n",
    "    df[\"neglog10_q\"] = -np.log10(df[\"Corrected P-Value\"].clip(lower=1e-300))\n",
    "    df[\"abs_effect\"] = df[\"Effect Size\"].abs()\n",
    "\n",
    "    # ----- Top N bar plot -----\n",
    "    top = df.sort_values(\"Corrected P-Value\").head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(top[\"Feature\"], top[\"neglog10_q\"])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"-log10(FDR q-value)\")\n",
    "    plt.title(f\"Top {top_n} Features - {outcome_name}\")\n",
    "    \n",
    "    # Annotate with test + effect size\n",
    "    for i, (_, row) in enumerate(top.iterrows()):\n",
    "        plt.text(row[\"neglog10_q\"], i, f\"  {row['Test Used']} | ES={row['Effect Size']:.2f}\", va=\"center\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(BASE_DIR, f\"univar_top{top_n}_{outcome_name}.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # ----- Volcano-style plot -----\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.scatter(df[\"abs_effect\"], df[\"neglog10_q\"], alpha=0.6)\n",
    "    plt.xlabel(\"Absolute Effect Size\")\n",
    "    plt.ylabel(\"-log10(FDR q-value)\")\n",
    "    plt.title(f\"Effect Size vs Significance - {outcome_name}\")\n",
    "    \n",
    "    # Label top N by significance\n",
    "    label_top = df.sort_values(\"Corrected P-Value\").head(label_n)\n",
    "    for _, row in label_top.iterrows():\n",
    "        plt.text(row[\"abs_effect\"], row[\"neglog10_q\"], f\" {row['Feature']}\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(BASE_DIR, f\"univar_volcano_{outcome_name}.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Return processed table\n",
    "    return df\n",
    "\n",
    "# Run to generate plots\n",
    "hosp_viz_df = plot_univariate_results(hosp_uni_results, \"Hospitalization\")\n",
    "adr_viz_df  = plot_univariate_results(adr_uni_results, \"Severe_ADR\")\n",
    "print(\"Visualizations completed! PNG files saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0100c5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap saved successfully!\n"
     ]
    }
   ],
   "source": [
    "combined = pd.concat([hosp_viz_df, adr_viz_df], ignore_index=True)\n",
    "\n",
    "heat = combined.pivot_table(\n",
    "    index=\"Feature\",\n",
    "    columns=\"Outcome\",\n",
    "    values=\"abs_effect\",\n",
    "    aggfunc=\"max\"\n",
    ")\n",
    "\n",
    "keep = heat.max(axis=1).sort_values(ascending=False).head(40).index\n",
    "heat = heat.loc[keep]\n",
    "\n",
    "plt.figure(figsize=(10, 0.3*len(heat)+4))\n",
    "plt.imshow(heat.fillna(0).values, aspect=\"auto\")\n",
    "plt.colorbar(label=\"|Effect Size|\")\n",
    "plt.xticks(range(len(heat.columns)), heat.columns, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(heat.index)), heat.index)\n",
    "plt.title(\"Effect Size Heatmap - Hospitalization & Severe ADR\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR,\"univar_effectsize_heatmap_hosp_ADR.png\"), dpi=240)\n",
    "plt.close()\n",
    "\n",
    "print(\"Heatmap saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b97dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_univariate_logistic(df, y_col, predictors, outcome_name, out_path):\n",
    "    \"\"\"\n",
    "    df: DataFrame with outcome + predictors\n",
    "    y_col: binary outcome column name\n",
    "    predictors: list of predictor names\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    # Ensure binary outcome is numeric 0/1\n",
    "    y = df[y_col].astype(int)\n",
    "\n",
    "    for var in predictors:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "\n",
    "        x = df[var]\n",
    "\n",
    "        # Skip constant or all missing\n",
    "        if x.isna().all():\n",
    "            continue\n",
    "        if x.nunique(dropna=True) < 2:\n",
    "            continue\n",
    "\n",
    "        # Numeric predictor\n",
    "        if pd.api.types.is_numeric_dtype(x):\n",
    "            X = sm.add_constant(x.astype(float))\n",
    "            try:\n",
    "                model = sm.Logit(y, X).fit(disp=False)\n",
    "                coef = model.params[var]\n",
    "                se = model.bse[var]\n",
    "                p = model.pvalues[var]\n",
    "                OR = np.exp(coef)\n",
    "                CI_low = np.exp(coef - 1.96 * se)\n",
    "                CI_high = np.exp(coef + 1.96 * se)\n",
    "\n",
    "                rows.append({\n",
    "                    \"Outcome\": outcome_name,\n",
    "                    \"Predictor\": var,\n",
    "                    \"Level\": \"per unit\",\n",
    "                    \"OR\": OR,\n",
    "                    \"CI_low\": CI_low,\n",
    "                    \"CI_high\": CI_high,\n",
    "                    \"p_value\": p\n",
    "                })\n",
    "            except Exception as e:\n",
    "                rows.append({\n",
    "                    \"Outcome\": outcome_name,\n",
    "                    \"Predictor\": var,\n",
    "                    \"Level\": \"per unit\",\n",
    "                    \"OR\": np.nan,\n",
    "                    \"CI_low\": np.nan,\n",
    "                    \"CI_high\": np.nan,\n",
    "                    \"p_value\": np.nan,\n",
    "                    \"Error\": str(e)\n",
    "                })\n",
    "\n",
    "        else:\n",
    "            # Categorical predictor: create dummies with most frequent as reference\n",
    "            tmp = df[[y_col, var]].dropna()\n",
    "            vc = tmp[var].value_counts()\n",
    "            if vc.shape[0] < 2:\n",
    "                continue\n",
    "\n",
    "            ref = vc.idxmax()\n",
    "            dummies = pd.get_dummies(tmp[var], drop_first=False)\n",
    "            # Drop reference column\n",
    "            dummies = dummies.drop(columns=[ref])\n",
    "            X = sm.add_constant(dummies)\n",
    "            y_sub = tmp[y_col].astype(int)\n",
    "\n",
    "            try:\n",
    "                model = sm.Logit(y_sub, X).fit(disp=False)\n",
    "                for lvl in dummies.columns:\n",
    "                    coef = model.params[lvl]\n",
    "                    se = model.bse[lvl]\n",
    "                    p = model.pvalues[lvl]\n",
    "                    OR = np.exp(coef)\n",
    "                    CI_low = np.exp(coef - 1.96 * se)\n",
    "                    CI_high = np.exp(coef + 1.96 * se)\n",
    "\n",
    "                    rows.append({\n",
    "                        \"Outcome\": outcome_name,\n",
    "                        \"Predictor\": var,\n",
    "                        \"Level\": f\"{lvl} vs {ref}\",\n",
    "                        \"OR\": OR,\n",
    "                        \"CI_low\": CI_low,\n",
    "                        \"CI_high\": CI_high,\n",
    "                        \"p_value\": p\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                rows.append({\n",
    "                    \"Outcome\": outcome_name,\n",
    "                    \"Predictor\": var,\n",
    "                    \"Level\": \"categorical\",\n",
    "                    \"OR\": np.nan,\n",
    "                    \"CI_low\": np.nan,\n",
    "                    \"CI_high\": np.nan,\n",
    "                    \"p_value\": np.nan,\n",
    "                    \"Error\": str(e)\n",
    "                })\n",
    "\n",
    "    uni_df = pd.DataFrame(rows)\n",
    "    if not uni_df.empty:\n",
    "        uni_df = uni_df.sort_values([\"Outcome\", \"Predictor\", \"p_value\"], na_position=\"last\")\n",
    "        uni_df.to_excel(out_path, index=False)\n",
    "        print(f\"[Univariate] Saved results to {out_path}\")\n",
    "    else:\n",
    "        print(\"[Univariate] No valid models fitted.\")\n",
    "\n",
    "    return uni_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41088906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def run_univariate_logistic(df, y_col, predictors, outcome_name, out_path):\n",
    "    \"\"\"\n",
    "    Univariate logistic regression for each predictor against a binary outcome.\n",
    "\n",
    "    df          : DataFrame with outcome + predictors\n",
    "    y_col       : name of binary outcome column (can be 0/1 or Yes/No etc.)\n",
    "    predictors  : list of predictor column names\n",
    "    outcome_name: label for reporting\n",
    "    out_path    : Excel path for saving results\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 1) Clean and encode outcome to numeric 0/1\n",
    "    # -------------------------------------------------\n",
    "    yes_no_map = {\n",
    "        \"yes\": 1, \"y\": 1, \"1\": 1, 1: 1, True: 1,\n",
    "        \"no\": 0, \"n\": 0, \"0\": 0, 0: 0, False: 0\n",
    "    }\n",
    "\n",
    "    # standardise strings then map\n",
    "    y_raw = (\n",
    "        data[y_col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .replace(yes_no_map)\n",
    "    )\n",
    "\n",
    "    y_num = pd.to_numeric(y_raw, errors=\"coerce\")\n",
    "\n",
    "    # keep only rows with 0/1\n",
    "    keep = y_num.isin([0, 1])\n",
    "    data = data.loc[keep].copy()\n",
    "    y = y_num.loc[keep].astype(int)\n",
    "\n",
    "    if data.empty or y.nunique() != 2:\n",
    "        print(f\"[{outcome_name}] Outcome '{y_col}' is not usable as binary after cleaning.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 2) Loop through predictors and fit univariate logit\n",
    "    # -------------------------------------------------\n",
    "    for var in predictors:\n",
    "        if var not in data.columns:\n",
    "            continue\n",
    "\n",
    "        sub = data[[var]].copy()\n",
    "        sub[\"y\"] = y\n",
    "\n",
    "        sub = sub.dropna()\n",
    "        if sub.empty or sub[\"y\"].nunique() != 2:\n",
    "            continue\n",
    "\n",
    "        X = sub[[var]]\n",
    "        y_sub = sub[\"y\"]\n",
    "\n",
    "        # if categorical, one-hot encode (drop_first=True)\n",
    "        if not np.issubdtype(X[var].dtype, np.number):\n",
    "            X = pd.get_dummies(X[var], drop_first=True, dummy_na=False, prefix=var)\n",
    "\n",
    "        # If after encoding there is no variation, skip\n",
    "        if X.shape[1] == 0 or X.nunique().max() <= 1:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # simple L2 logistic regression\n",
    "            lr = LogisticRegression(\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=1000\n",
    "            )\n",
    "            lr.fit(X, y_sub)\n",
    "\n",
    "            # For univariate, we report the effect of the main column\n",
    "            # If X has multiple dummies, we use the L2 norm of all coefs as \"effect size\"\n",
    "            coefs = lr.coef_.ravel()\n",
    "            effect_size = float(np.linalg.norm(coefs))\n",
    "            p_val = np.nan  # exact p-value needs statsmodels; we keep nan here or you can add it later\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Outcome\": outcome_name,\n",
    "                    \"Feature\": var,\n",
    "                    \"Test Used\": \"LogisticRegression\",\n",
    "                    \"Effect Size (|beta|)\": effect_size,\n",
    "                    \"P-Value\": p_val,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Outcome\": outcome_name,\n",
    "                    \"Feature\": var,\n",
    "                    \"Test Used\": \"Error\",\n",
    "                    \"Effect Size (|beta|)\": np.nan,\n",
    "                    \"P-Value\": np.nan,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 3) Optional FDR correction (only for non-NaN p-values)\n",
    "    #     (if you don't have p-values you can skip this)\n",
    "    # -------------------------------------------------\n",
    "    if not results_df.empty and results_df[\"P-Value\"].notna().any():\n",
    "        mask = results_df[\"P-Value\"].notna()\n",
    "        _, qvals, _, _ = multipletests(\n",
    "            results_df.loc[mask, \"P-Value\"],\n",
    "            alpha=0.05,\n",
    "            method=\"fdr_bh\",\n",
    "        )\n",
    "        results_df.loc[mask, \"Corrected P-Value\"] = qvals\n",
    "\n",
    "    # sort and save\n",
    "    if not results_df.empty:\n",
    "        sort_cols = [\"P-Value\"] if \"P-Value\" in results_df.columns else [\"Effect Size (|beta|)\"]\n",
    "        results_df = results_df.sort_values(sort_cols, na_position=\"last\")\n",
    "        results_df.to_excel(out_path, index=False)\n",
    "        print(f\"Univariate logistic for {outcome_name} saved to:\\n  {out_path}\")\n",
    "    else:\n",
    "        print(f\"No valid univariate logistic results for {outcome_name}.\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdad72b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\2704863988.py:30: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[y_col]\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\2704863988.py:129: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(out_path, index=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\2704863988.py:30: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[y_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate logistic for Hospitalization saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\univariate_logistic_hospitalization.xlsx\n",
      "Univariate logistic for Severe_ADR saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\univariate_logistic_severeADR.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\2704863988.py:129: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(out_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "hosp_uni_path = os.path.join(BIN_OUT_DIR, \"univariate_logistic_hospitalization.xlsx\")\n",
    "hosp_uni_results = run_univariate_logistic(\n",
    "    df=hosp_df,\n",
    "    y_col=\"hospitalization_flag\",\n",
    "    predictors=hosp_predictors,\n",
    "    outcome_name=\"Hospitalization\",\n",
    "    out_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "adr_uni_path = os.path.join(BIN_OUT_DIR, \"univariate_logistic_severeADR.xlsx\")\n",
    "adr_uni_results = run_univariate_logistic(\n",
    "    df=adr_model_df,\n",
    "    y_col=\"severe_adr_flag\",\n",
    "    predictors=adr_predictors,\n",
    "    outcome_name=\"Severe_ADR\",\n",
    "    out_path=adr_uni_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c37cf31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Hospitalization</h3><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Test Used</th>\n",
       "      <th>Effect Size (|beta|)</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>age_group</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.179189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>gender</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.142669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.612118</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>education_level</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.920244</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>employment_status</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.475946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>bmi_category</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.835104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>smoking_status_detail</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.403856</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>alcohol_consumption</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.634190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>IPB</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.572628</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>cci_score</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.071676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><hr><h3>Severe ADR</h3><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Test Used</th>\n",
       "      <th>Effect Size (|beta|)</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>age_group</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.724274</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>gender</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.360540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.324784</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>education_level</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.706786</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>employment_status</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.545035</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>bmi_category</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.650833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>smoking_status_detail</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.693905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>alcohol_consumption</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.907816</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>IPB</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.290090</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>cci_score</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.160818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\n",
    "    \"<h3>Hospitalization</h3>\"\n",
    "    + hosp_uni_results.head(10).to_html()\n",
    "    + \"<hr><h3>Severe ADR</h3>\"\n",
    "    + adr_uni_results.head(10).to_html()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee41cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d64d2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_binary_outcome(df, y_col):\n",
    "    \"\"\"\n",
    "    Map outcome column to numeric 0/1 and drop invalid rows.\n",
    "    Handles strings like 'Yes'/'No', '1'/'0', True/False.\n",
    "    \"\"\"\n",
    "    yes_no_map = {\n",
    "        \"yes\": 1, \"y\": 1, \"1\": 1, 1: 1, True: 1,\n",
    "        \"present\": 1, \"present / yes\": 1, \"present/yes\": 1, \"positive\": 1,\n",
    "        \"no\": 0, \"n\": 0, \"0\": 0, 0: 0, False: 0,\n",
    "        \"absent\": 0, \"absent / no\": 0, \"absent/no\": 0, \"negative\": 0,\n",
    "    }\n",
    "\n",
    "    y_raw = (\n",
    "        df[y_col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .replace(yes_no_map)\n",
    "    )\n",
    "    y_num = pd.to_numeric(y_raw, errors=\"coerce\")\n",
    "\n",
    "    keep = y_num.isin([0, 1])\n",
    "    df_clean = df.loc[keep].copy()\n",
    "    y_clean = y_num.loc[keep].astype(int)\n",
    "\n",
    "    return df_clean, y_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c721e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_design_and_fit_logreg(\n",
    "    df,\n",
    "    y_col,\n",
    "    predictors,\n",
    "    outcome_name,\n",
    "    out_prefix,\n",
    "    out_dir,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fit a multivariable logistic regression with preprocessing and\n",
    "    compute evaluation metrics (AUC, ROC, accuracy, etc).\n",
    "\n",
    "    Returns:\n",
    "      model      : fitted sklearn Pipeline\n",
    "      metrics_df : single-row DataFrame with metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # Subset to outcome + predictors\n",
    "    cols = [c for c in predictors if c in df.columns]\n",
    "    data = df[[y_col] + cols].copy()\n",
    "\n",
    "    # Clean outcome to 0/1 and drop invalid rows\n",
    "    data, y = clean_binary_outcome(data, y_col)\n",
    "    if data.empty or y.nunique() != 2:\n",
    "        raise ValueError(f\"[{outcome_name}] outcome '{y_col}' is not usable as binary after cleaning.\")\n",
    "\n",
    "    # Split predictors from outcome\n",
    "    X = data[cols]\n",
    "\n",
    "    # Identify numeric vs categorical predictors\n",
    "    numeric_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
    "    cat_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "    # Preprocessor: scale numeric, one-hot encode categoricals\n",
    "    transformers = []\n",
    "    if numeric_cols:\n",
    "        transformers.append(\n",
    "            (\"num\", StandardScaler(), numeric_cols)\n",
    "        )\n",
    "    if cat_cols:\n",
    "        transformers.append(\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "        )\n",
    "\n",
    "    if not transformers:\n",
    "        raise ValueError(f\"[{outcome_name}] No valid predictors after type detection.\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "    # Logistic regression model\n",
    "    clf = LogisticRegression(\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000,\n",
    "    )\n",
    "\n",
    "    model = Pipeline(\n",
    "        steps=[\n",
    "            (\"pre\", preprocessor),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and probabilities\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    auc_roc = roc_auc_score(y_test, y_prob)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    ap = average_precision_score(y_test, y_prob)\n",
    "    brier = brier_score_loss(y_test, y_prob)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"Outcome\": outcome_name,\n",
    "        \"AUC_ROC\": auc_roc,\n",
    "        \"AP_PR\": ap,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1\": f1,\n",
    "        \"Brier_Score\": brier,\n",
    "        \"TN\": cm[0, 0],\n",
    "        \"FP\": cm[0, 1],\n",
    "        \"FN\": cm[1, 0],\n",
    "        \"TP\": cm[1, 1],\n",
    "        \"Test_Size\": len(y_test),\n",
    "        \"Train_Size\": len(y_train),\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "\n",
    "    # Make sure output directory exists\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Save metrics to Excel\n",
    "    metrics_path = os.path.join(out_dir, f\"{out_prefix}_logistic_metrics.xlsx\")\n",
    "    metrics_df.to_excel(metrics_path, index=False)\n",
    "\n",
    "    # Save ROC curve points (optional but useful)\n",
    "    roc_df = pd.DataFrame(\n",
    "        {\"FPR\": fpr, \"TPR\": tpr, \"Threshold\": thresholds}\n",
    "    )\n",
    "    roc_path = os.path.join(out_dir, f\"{out_prefix}_ROC_points.xlsx\")\n",
    "    roc_df.to_excel(roc_path, index=False)\n",
    "\n",
    "    # Plot ROC curve and save\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc_roc:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve - {outcome_name}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    roc_png_path = os.path.join(out_dir, f\"{out_prefix}_ROC_curve.png\")\n",
    "    plt.savefig(roc_png_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"[{outcome_name}] AUC_ROC: {auc_roc:.3f}, Accuracy: {acc:.3f}, F1: {f1:.3f}\")\n",
    "    print(f\"[{outcome_name}] Metrics saved to: {metrics_path}\")\n",
    "    print(f\"[{outcome_name}] ROC curve saved to: {roc_png_path}\")\n",
    "    print(f\"[{outcome_name}] ROC points saved to: {roc_path}\")\n",
    "\n",
    "    return model, metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd5a6319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\1251126521.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[y_col]\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\2936355028.py:119: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  metrics_df.to_excel(metrics_path, index=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\2936355028.py:126: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  roc_df.to_excel(roc_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hospitalization] AUC_ROC: 0.546, Accuracy: 0.762, F1: 0.121\n",
      "[Hospitalization] Metrics saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\hosp_logistic_metrics.xlsx\n",
      "[Hospitalization] ROC curve saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\hosp_ROC_curve.png\n",
      "[Hospitalization] ROC points saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\hosp_ROC_points.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>AUC_ROC</th>\n",
       "      <th>AP_PR</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Brier_Score</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Test_Size</th>\n",
       "      <th>Train_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>0.546377</td>\n",
       "      <td>0.310056</td>\n",
       "      <td>0.762295</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.201599</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Outcome   AUC_ROC     AP_PR  Accuracy  Precision    Recall  \\\n",
       "0  Hospitalization  0.546377  0.310056  0.762295   0.666667  0.066667   \n",
       "\n",
       "         F1  Brier_Score  TN  FP  FN  TP  Test_Size  Train_Size  \n",
       "0  0.121212     0.201599  91   1  28   2        122         284  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\1251126521.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[y_col]\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\2936355028.py:119: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  metrics_df.to_excel(metrics_path, index=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\2936355028.py:126: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  roc_df.to_excel(roc_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Severe_ADR] AUC_ROC: 0.595, Accuracy: 0.772, F1: 0.000\n",
      "[Severe_ADR] Metrics saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\adr_logistic_metrics.xlsx\n",
      "[Severe_ADR] ROC curve saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\adr_ROC_curve.png\n",
      "[Severe_ADR] ROC points saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\adr_ROC_points.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>AUC_ROC</th>\n",
       "      <th>AP_PR</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Brier_Score</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Test_Size</th>\n",
       "      <th>Train_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.269119</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171593</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Outcome   AUC_ROC     AP_PR  Accuracy  Precision  Recall   F1  \\\n",
       "0  Severe_ADR  0.595238  0.269119  0.772152        0.0     0.0  0.0   \n",
       "\n",
       "   Brier_Score  TN  FP  FN  TP  Test_Size  Train_Size  \n",
       "0     0.171593  61   2  16   0         79         182  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# HOSPITALIZATION: multivariable logistic + metrics\n",
    "# -------------------------------------------------------------\n",
    "hosp_model, hosp_metrics = build_design_and_fit_logreg(\n",
    "    df=hosp_df,\n",
    "    y_col=\"hospitalization_flag\",\n",
    "    predictors=hosp_predictors,\n",
    "    outcome_name=\"Hospitalization\",\n",
    "    out_prefix=\"hosp\",\n",
    "    out_dir=BIN_OUT_DIR,\n",
    ")\n",
    "\n",
    "display(hosp_metrics)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# SEVERE ADR: multivariable logistic + metrics\n",
    "# -------------------------------------------------------------\n",
    "adr_model, adr_metrics = build_design_and_fit_logreg(\n",
    "    df=adr_model_df,\n",
    "    y_col=\"severe_adr_flag\",\n",
    "    predictors=adr_predictors,\n",
    "    outcome_name=\"Severe_ADR\",\n",
    "    out_prefix=\"adr\",\n",
    "    out_dir=BIN_OUT_DIR,\n",
    ")\n",
    "\n",
    "display(adr_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d78dcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Helper: clean a binary outcome to 0/1\n",
    "# -------------------------------------------------------------\n",
    "def clean_binary_outcome(df, col):\n",
    "    \"\"\"\n",
    "    Map common yes/no style values to 0/1 and drop everything else.\n",
    "    Returns (clean_df, y) where:\n",
    "      - clean_df is restricted to rows with valid outcome\n",
    "      - y is an integer Series of 0/1 aligned with clean_df\n",
    "    \"\"\"\n",
    "    yes_no_map = {\n",
    "        \"yes\": 1, \"y\": 1, \"present\": 1, \"present / yes\": 1, \"present/yes\": 1,\n",
    "        \"1\": 1, 1: 1, True: 1,\n",
    "        \"no\": 0, \"n\": 0, \"absent\": 0, \"absent / no\": 0, \"absent/no\": 0,\n",
    "        \"0\": 0, 0: 0, False: 0\n",
    "    }\n",
    "\n",
    "    raw = df[col].astype(str).str.lower().str.strip().replace(yes_no_map)\n",
    "    y_num = pd.to_numeric(raw, errors=\"coerce\")\n",
    "\n",
    "    keep = y_num.isin([0, 1])\n",
    "    clean_df = df.loc[keep].copy()\n",
    "    y = y_num.loc[keep].astype(int)\n",
    "\n",
    "    return clean_df, y\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Univariate logistic regression for each predictor\n",
    "# -------------------------------------------------------------\n",
    "def run_univariate_logistic(df, y_col, predictors, outcome_name, out_path):\n",
    "    \"\"\"\n",
    "    df          : DataFrame with outcome + predictors\n",
    "    y_col       : binary outcome column name (can be 0/1 or Yes/No etc.)\n",
    "    predictors  : list of predictor names\n",
    "    outcome_name: label for reporting\n",
    "    out_path    : path to Excel file\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Clean outcome to 0/1 and restrict df\n",
    "    data, y = clean_binary_outcome(df, y_col)\n",
    "\n",
    "    if data.empty or y.nunique() != 2:\n",
    "        print(f\"[{outcome_name}] Outcome {y_col} unusable as binary after cleaning.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for var in predictors:\n",
    "        if var not in data.columns:\n",
    "            continue\n",
    "\n",
    "        # subset with var + y, drop missing\n",
    "        sub = data[[var]].copy()\n",
    "        sub[\"y\"] = y\n",
    "        sub = sub.dropna()\n",
    "\n",
    "        if sub.empty or sub[\"y\"].nunique() != 2:\n",
    "            continue\n",
    "\n",
    "        x = sub[var]\n",
    "        y_sub = sub[\"y\"]\n",
    "\n",
    "        # Decide: treat as numeric or categorical\n",
    "        # Rule: if numeric AND more than 10 unique values -> numeric\n",
    "        # else treat as categorical\n",
    "        is_num = pd.api.types.is_numeric_dtype(x) and x.nunique(dropna=True) > 10\n",
    "\n",
    "        try:\n",
    "            if is_num:\n",
    "                # -------------- Numeric predictor --------------\n",
    "                X = sm.add_constant(pd.to_numeric(x, errors=\"coerce\"))\n",
    "                # drop rows with any NaN in X or y\n",
    "                valid = X.notna().all(axis=1) & y_sub.notna()\n",
    "                X = X.loc[valid]\n",
    "                y_valid = y_sub.loc[valid]\n",
    "\n",
    "                if len(y_valid) == 0 or y_valid.nunique() != 2:\n",
    "                    continue\n",
    "\n",
    "                model = sm.Logit(y_valid, X).fit(disp=False)\n",
    "                coef = model.params[var]\n",
    "                se = model.bse[var]\n",
    "                p = model.pvalues[var]\n",
    "                OR = np.exp(coef)\n",
    "                CI_low = np.exp(coef - 1.96 * se)\n",
    "                CI_high = np.exp(coef + 1.96 * se)\n",
    "\n",
    "                results.append({\n",
    "                    \"Outcome\": outcome_name,\n",
    "                    \"Feature\": var,\n",
    "                    \"Level\": \"per unit\",\n",
    "                    \"coef\": coef,\n",
    "                    \"OR\": OR,\n",
    "                    \"CI_low\": CI_low,\n",
    "                    \"CI_high\": CI_high,\n",
    "                    \"p_value\": p\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                # -------------- Categorical predictor --------------\n",
    "                x_cat = x.astype(str)\n",
    "                vc = x_cat.value_counts()\n",
    "\n",
    "                # need at least 2 levels\n",
    "                if vc.shape[0] < 2:\n",
    "                    continue\n",
    "\n",
    "                # choose most frequent category as reference\n",
    "                ref = vc.idxmax()\n",
    "\n",
    "                dummies = pd.get_dummies(x_cat, drop_first=False, prefix=var)\n",
    "\n",
    "                # reference column name\n",
    "                ref_col = f\"{var}_{ref}\"\n",
    "                if ref_col in dummies.columns:\n",
    "                    dummies = dummies.drop(columns=[ref_col])\n",
    "\n",
    "                # if no columns left after dropping ref, skip\n",
    "                if dummies.shape[1] == 0:\n",
    "                    continue\n",
    "\n",
    "                X = sm.add_constant(dummies)\n",
    "                # align y_sub and drop any NaN row\n",
    "                valid = X.notna().all(axis=1) & y_sub.notna()\n",
    "                X = X.loc[valid]\n",
    "                y_valid = y_sub.loc[valid]\n",
    "\n",
    "                if len(y_valid) == 0 or y_valid.nunique() != 2:\n",
    "                    continue\n",
    "\n",
    "                model = sm.Logit(y_valid, X).fit(disp=False)\n",
    "\n",
    "                for col in dummies.columns:\n",
    "                    coef = model.params[col]\n",
    "                    se = model.bse[col]\n",
    "                    p = model.pvalues[col]\n",
    "                    OR = np.exp(coef)\n",
    "                    CI_low = np.exp(coef - 1.96 * se)\n",
    "                    CI_high = np.exp(coef + 1.96 * se)\n",
    "\n",
    "                    # pretty level name\n",
    "                    level_name = col.replace(f\"{var}_\", \"\")\n",
    "                    results.append({\n",
    "                        \"Outcome\": outcome_name,\n",
    "                        \"Feature\": var,\n",
    "                        \"Level\": f\"{level_name} vs {ref}\",\n",
    "                        \"coef\": coef,\n",
    "                        \"OR\": OR,\n",
    "                        \"CI_low\": CI_low,\n",
    "                        \"CI_high\": CI_high,\n",
    "                        \"p_value\": p\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            # keep track of failures\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_name,\n",
    "                \"Feature\": var,\n",
    "                \"Level\": \"ERROR\",\n",
    "                \"coef\": np.nan,\n",
    "                \"OR\": np.nan,\n",
    "                \"CI_low\": np.nan,\n",
    "                \"CI_high\": np.nan,\n",
    "                \"p_value\": np.nan,\n",
    "                \"Error\": str(e)\n",
    "            })\n",
    "\n",
    "    uni_df = pd.DataFrame(results)\n",
    "\n",
    "    if uni_df.empty:\n",
    "        print(f\"[Univariate logistic] No valid models for {outcome_name}.\")\n",
    "        return uni_df\n",
    "\n",
    "    # 3) FDR correction on p-values\n",
    "    mask = uni_df[\"p_value\"].notna()\n",
    "    if mask.any():\n",
    "        _, qvals, _, _ = multipletests(\n",
    "            uni_df.loc[mask, \"p_value\"],\n",
    "            alpha=0.05,\n",
    "            method=\"fdr_bh\"\n",
    "        )\n",
    "        uni_df.loc[mask, \"q_value_fdr_bh\"] = qvals\n",
    "\n",
    "    # 4) Sort and save\n",
    "    uni_df = uni_df.sort_values([\"p_value\"], na_position=\"last\")\n",
    "    uni_df.to_excel(out_path, index=False)\n",
    "\n",
    "    print(f\"[Univariate logistic] {outcome_name} results saved to:\\n  {out_path}\")\n",
    "\n",
    "    return uni_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27deeae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\3574143870.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw = df[col].astype(str).str.lower().str.strip().replace(yes_no_map)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\3574143870.py:193: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  uni_df.to_excel(out_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Univariate logistic] Hospitalization results saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\univariate_logistic_Hospitalization_with_OR.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\3574143870.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw = df[col].astype(str).str.lower().str.strip().replace(yes_no_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Univariate logistic] Severe_ADR results saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\univariate_logistic_SevereADR_with_OR.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\3574143870.py:193: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  uni_df.to_excel(out_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "# Hospitalization\n",
    "hosp_uni_path = os.path.join(BIN_OUT_DIR, \"univariate_logistic_Hospitalization_with_OR.xlsx\")\n",
    "hosp_uni_results = run_univariate_logistic(\n",
    "    df=hosp_df,\n",
    "    y_col=\"hospitalization_flag\",\n",
    "    predictors=hosp_predictors,\n",
    "    outcome_name=\"Hospitalization\",\n",
    "    out_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "# Severe ADR\n",
    "adr_uni_path = os.path.join(BIN_OUT_DIR, \"univariate_logistic_SevereADR_with_OR.xlsx\")\n",
    "adr_uni_results = run_univariate_logistic(\n",
    "    df=adr_model_df,\n",
    "    y_col=\"severe_adr_flag\",\n",
    "    predictors=adr_predictors,\n",
    "    outcome_name=\"Severe_ADR\",\n",
    "    out_path=adr_uni_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dab3de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from adjustText import adjust_text\n",
    "    HAS_ADJUSTTEXT = True\n",
    "except Exception:\n",
    "    HAS_ADJUSTTEXT = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "435fe9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "Q_THRESH = 0.05\n",
    "MAX_LABELS = 12\n",
    "EXCLUDE_REGEX = r\"(Intercept|_nan\\b|_RARE\\b)\"\n",
    "\n",
    "def pretty_label(s: str) -> str:\n",
    "    s = str(s).replace(\"_\", \" \")\n",
    "    s = \" \".join(s.split())\n",
    "    s = s.replace(\"white blood cells range\", \"WBC range\")\n",
    "    s = s.replace(\"red blood cells range\", \"RBC range\")\n",
    "    s = s.replace(\"hemoglobin range\", \"Hb range\")\n",
    "    s = s.replace(\"platelet count range\", \"Platelets range\")\n",
    "    s = s.replace(\"neutrophils percent range\", \"Neutrophils range\")\n",
    "    return s\n",
    "\n",
    "def plot_clean_volcano_from_uni(\n",
    "    df,\n",
    "    outcome_name,\n",
    "    plot_dir,\n",
    "    q_col=None,                 # e.g., \"q_value_fdr_bh\" or \"q_value_fdr_bh\" (ADR)\n",
    "    p_col=\"p_value\",            # raw p\n",
    "    effect_col=\"coef\",          # signed effect\n",
    "    feature_col=\"Feature\",\n",
    "    extra_exclude_regex=None,\n",
    "    winsor_q=(0.02, 0.98),\n",
    "    max_labels=MAX_LABELS\n",
    "):\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    df = df.copy()\n",
    "\n",
    "    # Filter by outcome if the column exists\n",
    "    if \"Outcome\" in df.columns:\n",
    "        df = df[df[\"Outcome\"] == outcome_name].copy()\n",
    "\n",
    "    # Drop junk features\n",
    "    pat = EXCLUDE_REGEX\n",
    "    if extra_exclude_regex:\n",
    "        pat = f\"({pat}|{extra_exclude_regex})\"\n",
    "    df = df[~df[feature_col].astype(str).str.contains(pat, case=False, na=False)].copy()\n",
    "\n",
    "    # Ensure numeric\n",
    "    df[\"effect\"] = pd.to_numeric(df[effect_col], errors=\"coerce\")\n",
    "    df[\"pval\"]   = pd.to_numeric(df[p_col], errors=\"coerce\")\n",
    "\n",
    "    # Compute q-values if missing\n",
    "    if q_col is None or q_col not in df.columns:\n",
    "        # BH-FDR correction\n",
    "        p = df[\"pval\"].values\n",
    "        mask = np.isfinite(p)\n",
    "        q = np.full_like(p, np.nan, dtype=float)\n",
    "\n",
    "        if mask.sum() > 0:\n",
    "            p_valid = p[mask]\n",
    "            order = np.argsort(p_valid)\n",
    "            ranked = p_valid[order]\n",
    "            m = len(ranked)\n",
    "            bh = ranked * m / (np.arange(1, m + 1))\n",
    "            bh = np.minimum.accumulate(bh[::-1])[::-1]\n",
    "            bh = np.clip(bh, 0, 1)\n",
    "\n",
    "            q_valid = np.empty_like(bh)\n",
    "            q_valid[order] = bh\n",
    "            q[mask] = q_valid\n",
    "\n",
    "        df[\"qval\"] = q\n",
    "        q_used = \"computed_BH_FDR\"\n",
    "    else:\n",
    "        df[\"qval\"] = pd.to_numeric(df[q_col], errors=\"coerce\")\n",
    "        q_used = q_col\n",
    "\n",
    "    df = df.dropna(subset=[\"effect\", \"qval\"]).copy()\n",
    "    if df.empty:\n",
    "        print(f\"[{outcome_name}] No usable rows after cleaning.\")\n",
    "        return\n",
    "\n",
    "    df[\"neglog10_q\"] = -np.log10(df[\"qval\"].clip(lower=1e-300))\n",
    "    df[\"_abs_eff\"] = df[\"effect\"].abs()\n",
    "\n",
    "    sig = df[\"qval\"] < Q_THRESH\n",
    "    up = sig & (df[\"effect\"] > 0)\n",
    "    down = sig & (df[\"effect\"] < 0)\n",
    "    nonsig = ~sig\n",
    "\n",
    "    # Label selection: significant first, then large effect\n",
    "    sig_pool = df[sig].sort_values([\"qval\", \"_abs_eff\"], ascending=[True, False])\n",
    "    if len(sig_pool) >= max_labels:\n",
    "        label_df = sig_pool.head(max_labels)\n",
    "    else:\n",
    "        fill = df.sort_values([\"_abs_eff\", \"qval\"], ascending=[False, True]).head(max_labels)\n",
    "        label_df = pd.concat([sig_pool, fill]).drop_duplicates().head(max_labels)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    plt.scatter(df.loc[nonsig, \"effect\"], df.loc[nonsig, \"neglog10_q\"],\n",
    "                s=28, alpha=0.25, label=\"Not significant\")\n",
    "\n",
    "    plt.scatter(df.loc[up, \"effect\"], df.loc[up, \"neglog10_q\"],\n",
    "                s=45, alpha=0.9, label=f\"q<{Q_THRESH}, coef>0\")\n",
    "\n",
    "    plt.scatter(df.loc[down, \"effect\"], df.loc[down, \"neglog10_q\"],\n",
    "                s=45, alpha=0.9, label=f\"q<{Q_THRESH}, coef<0\")\n",
    "\n",
    "    plt.axhline(-np.log10(Q_THRESH), linestyle=\"--\", linewidth=1)\n",
    "    plt.axvline(0.0, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # Winsorized x limits (prevents one outlier from destroying plot)\n",
    "    x = df[\"effect\"].values\n",
    "    if len(x) > 10:\n",
    "        lo, hi = np.quantile(x, winsor_q)\n",
    "        max_abs = max(abs(lo), abs(hi)) * 1.35\n",
    "    else:\n",
    "        max_abs = max(abs(x.min()), abs(x.max())) * 1.35\n",
    "    max_abs = max(max_abs, 0.1)\n",
    "    plt.xlim(-max_abs, max_abs)\n",
    "\n",
    "    plt.xlabel(\"Effect size (signed coef)\")\n",
    "    plt.ylabel(f\"-log10(q-value) [{q_used}]\")\n",
    "    plt.title(f\"Volcano plot – {outcome_name}\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=8, frameon=False)\n",
    "\n",
    "    texts = []\n",
    "    for _, row in label_df.iterrows():\n",
    "        texts.append(\n",
    "            plt.text(row[\"effect\"], row[\"neglog10_q\"], pretty_label(row[feature_col]), fontsize=9)\n",
    "        )\n",
    "\n",
    "    if HAS_ADJUSTTEXT and texts:\n",
    "        adjust_text(\n",
    "            texts,\n",
    "            expand_points=(1.2, 1.4),\n",
    "            expand_text=(1.2, 1.4),\n",
    "            arrowprops=dict(arrowstyle=\"-\", lw=0.8),\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(plot_dir, f\"univariate_volcano_{outcome_name}_clean.png\")\n",
    "    plt.savefig(out_png, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Export labels\n",
    "    out_xlsx = os.path.join(plot_dir, f\"univariate_volcano_{outcome_name}_labels.xlsx\")\n",
    "    label_export = label_df[[feature_col, \"effect\", \"qval\", \"neglog10_q\", \"pval\"]].copy()\n",
    "    label_export.rename(columns={feature_col: \"Feature\"}, inplace=True)\n",
    "    label_export.to_excel(out_xlsx, index=False)\n",
    "\n",
    "    print(\"Saved:\", out_png)\n",
    "    print(\"Labels:\", out_xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62e12d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\3459458369.py:43: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[~df[feature_col].astype(str).str.contains(pat, case=False, na=False)].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\univariate_volcano_Severe_ADR_clean.png\n",
      "Labels: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\univariate_volcano_Severe_ADR_labels.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\3459458369.py:149: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  label_export.to_excel(out_xlsx, index=False)\n"
     ]
    }
   ],
   "source": [
    "plot_clean_volcano_from_uni(\n",
    "    df=adr_uni_results,\n",
    "    outcome_name=\"Severe_ADR\",  # must match your Outcome values\n",
    "    plot_dir=r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\",\n",
    "    q_col=\"q_value_fdr_bh\",\n",
    "    p_col=\"p_value\",\n",
    "    effect_col=\"coef\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78df0b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Severe_ADR']\n",
      "['Hospitalization']\n"
     ]
    }
   ],
   "source": [
    "print(adr_uni_results[\"Outcome\"].unique())\n",
    "print(hosp_uni_results[\"Outcome\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5929b165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hospitalization] No usable rows after cleaning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13176\\3459458369.py:43: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[~df[feature_col].astype(str).str.contains(pat, case=False, na=False)].copy()\n"
     ]
    }
   ],
   "source": [
    "plot_clean_volcano_from_uni(\n",
    "    df=hosp_uni_results,\n",
    "    outcome_name=\"Hospitalization\",  # must match your Outcome values\n",
    "    plot_dir=r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\",\n",
    "    q_col=None,      # forces computing BH-FDR\n",
    "    p_col=\"p_value\",\n",
    "    effect_col=\"coef\",\n",
    "    extra_exclude_regex=r\"(hospitalization_count|valid_hospitalization_count|\\bcount\\b|\\bn_\\b)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138bd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
